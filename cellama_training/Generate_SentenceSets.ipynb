{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e95ebb85-5e16-4fd6-b740-7c7ad370d621",
   "metadata": {},
   "source": [
    "## Example for FineTuning Transformer Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "782d3d56-a71e-49e8-a906-0a4a3fa3d1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, models\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from cellama import cell_to_sentence\n",
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "997de634-12a0-45ef-801e-d8a097e1d789",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import InputExample\n",
    "from random import randint, sample, choices, shuffle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e111b041-2df1-413c-a5e0-bfb788bfe25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_ts = sc.read_h5ad('../Tabula_Sapiens_Subsample/Tabula_sapiens_10subsample_raw_counts.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a844049-6b7b-4d30-bdf1-b783c37633fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence Generation Parameters \n",
    "top_k = 16\n",
    "obs_features = None\n",
    "num_samples = adata_ts.shape[0]\n",
    "n_hvgs= 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9bc0d8c-ce66-4c32-8738-d12f48e8da57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process to var have gene name index\n",
    "adata_ts.var.index = adata_ts.var.feature_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce5b0530-cf0a-4bef-8706-461004709a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/lang/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py:226: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  disp_grouped = df.groupby(\"mean_bin\")[\"dispersions\"]\n"
     ]
    }
   ],
   "source": [
    "#Preprocess adata_ts\n",
    "\n",
    "adata_ts.layers[\"counts\"] = adata_ts.X.copy()\n",
    "sc.pp.normalize_total(adata_ts)\n",
    "# Logarithmize the data\n",
    "sc.pp.log1p(adata_ts)\n",
    "sc.pp.highly_variable_genes(adata_ts, n_top_genes=n_hvgs)\n",
    "sc.tl.pca(adata_ts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1e719f5-af74-4921-abc0-5e18c08bf4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_ts_ = adata_ts[:,adata_ts.var.highly_variable]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b221ccd7-cdc4-4846-98bc-45f73da07e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Top genes are FTH1, CSTA, ATG3, FLI1, RETN, PRAM1, ITGAM, TNNT1, ARHGAP45, GLB1, DDX60L, SNX30, ELF2, SNX20, NLRC4, and UBE2D2.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example SEntence\n",
    "top_genes_sentences = cell_to_sentence(adata_ts_, top_k, obs_features)\n",
    "sentences = list(top_genes_sentences.values())\n",
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7239f19a-235b-49ae-80bb-e26fafd56846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_data(adata, sentences, num_samples=10000, top_k=10, similarity_ratio=0.5, \n",
    "                           batch_random_sampling=100, obs_features=None):\n",
    "    '''\n",
    "    Generates training data by creating pairs of sentences with associated cosine similarity scores,\n",
    "    modified based on the difference in specified observation features.\n",
    "\n",
    "    Parameters:\n",
    "        adata (AnnData): The annotated data matrix which includes PCA data under .obsm['X_pca'].\n",
    "        sentences (list): List of sentences corresponding to the rows in `adata`.\n",
    "        num_samples (int): Total number of samples to generate.\n",
    "        top_k (int): Number of high similarity samples to consider for each base sample.\n",
    "        similarity_ratio (float): Proportion of the total samples that should be high similarity pairs.\n",
    "        batch_random_sampling (int): Number of random samples to process in each batch for random pairs.\n",
    "        obs_features (list): List of observation features to consider when adjusting similarity values.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of InputExample objects, each containing a pair of sentences and a similarity label.\n",
    "    '''\n",
    "    pca_data = adata.obsm['X_pca']\n",
    "    num_cells = pca_data.shape[0]\n",
    "    training_examples = []\n",
    "    num_similarity_samples = int(num_samples * similarity_ratio)\n",
    "    num_random_samples = num_samples - num_similarity_samples\n",
    "\n",
    "    def check_features(idx1, idx2):\n",
    "        ''' Check if any of the observation features are different between two indices '''\n",
    "        if obs_features is None:\n",
    "            return True\n",
    "        for feature in obs_features:\n",
    "            if adata.obs[feature].iloc[idx1] != adata.obs[feature].iloc[idx2]:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    # Generate high similarity samples\n",
    "    for _ in range(num_similarity_samples // top_k):\n",
    "        idx1 = randint(0, num_cells - 1)\n",
    "        similarities = cosine_similarity([pca_data[idx1]], pca_data)[0]\n",
    "        top_k_indices = np.argsort(-similarities)[1:top_k+1]  # Skip the self-match at 0 position\n",
    "\n",
    "        for idx2 in top_k_indices:\n",
    "            if check_features(idx1, idx2):\n",
    "                cos_sim = similarities[idx2]\n",
    "            else:\n",
    "                cos_sim = 0  # Set similarity to 0 if observation features differ\n",
    "            example = InputExample(texts=[sentences[idx1], sentences[idx2]], label=float(cos_sim))\n",
    "            training_examples.append(example)\n",
    "\n",
    "    # Generate random samples using batch processing\n",
    "    for _ in range(num_random_samples // batch_random_sampling):\n",
    "        idx1 = randint(0, num_cells - 1)\n",
    "        idx2s = choices(range(num_cells), k=batch_random_sampling)\n",
    "        #idx2s = [idx2 for idx2 in idx2s if idx2 != idx1 and check_features(idx1, idx2)]  # Filter idx2s\n",
    "\n",
    "        cos_sims = cosine_similarity([pca_data[idx1]], pca_data[idx2s])[0]\n",
    "\n",
    "        for idx2, cos_sim in zip(idx2s, cos_sims):\n",
    "            if not check_features(idx1, idx2):\n",
    "                cos_sim = 0  # Adjust similarity based on observation features\n",
    "            example = InputExample(texts=[sentences[idx1], sentences[idx2]], label=float(cos_sim))\n",
    "            training_examples.append(example)\n",
    "\n",
    "    shuffled_examples = sample(training_examples, len(training_examples))\n",
    "    return shuffled_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "03ac3797-8d09-401b-91a3-f594087cb67d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........ 16 None\n",
      "\t\t sentence generation done\n",
      "\t\t train_exmaples generated\n",
      "........ 16 ['organ_tissue']\n",
      "\t\t sentence generation done\n",
      "\t\t train_exmaples generated\n",
      "........ 16 ['method', 'organ_tissue']\n",
      "\t\t sentence generation done\n",
      "\t\t train_exmaples generated\n",
      "........ 20 None\n",
      "\t\t sentence generation done\n",
      "\t\t train_exmaples generated\n",
      "........ 20 ['organ_tissue']\n",
      "\t\t sentence generation done\n",
      "\t\t train_exmaples generated\n",
      "........ 20 ['method', 'organ_tissue']\n",
      "\t\t sentence generation done\n",
      "\t\t train_exmaples generated\n",
      "........ 24 None\n",
      "\t\t sentence generation done\n",
      "\t\t train_exmaples generated\n",
      "........ 24 ['organ_tissue']\n",
      "\t\t sentence generation done\n",
      "\t\t train_exmaples generated\n",
      "........ 24 ['method', 'organ_tissue']\n",
      "\t\t sentence generation done\n",
      "\t\t train_exmaples generated\n"
     ]
    }
   ],
   "source": [
    "#Generate Training Examples --> Only Do Once and Save to Json \n",
    "top_k_values = [16, 20, 24]\n",
    "obs_features_options = [None, ['organ_tissue'], ['method', 'organ_tissue']]\n",
    "\n",
    "train_examples = []  # This will store all training examples across all configurations\n",
    "\n",
    "for top_k in top_k_values:\n",
    "    for features in obs_features_options:\n",
    "        print('........',top_k, features ) \n",
    "        # Generate sentences for the current configuration\n",
    "        sentences = list(cell_to_sentence(adata_ts_, top_k, features).values())\n",
    "        print('\\t\\t sentence generation done')\n",
    "        # Generate training data using these sentences and the current PCA settings\n",
    "        current_examples = generate_training_data(adata_ts_, sentences, num_samples=num_samples, obs_features=features)\n",
    "        train_examples.extend(current_examples)\n",
    "        print('\\t\\t train_exmaples generated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a09be3fc-4d29-4b7d-aeef-c9b6e6c2070c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Examples\n",
    "from _examples_to_json import save_examples_to_json, load_examples_from_json\n",
    "\n",
    "save_examples_to_json(train_examples, 'ts_sample_train_examples.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5094a3a-3e32-46af-8a99-67995f4f71f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After Generation, Only using this\n",
    "from _examples_to_json import save_examples_to_json, load_examples_from_json\n",
    "train_examples = load_examples_from_json('ts_sample_train_examples.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9fe18324-a2f0-4046-85a3-4efb57c4b5e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts: ['Top genes are FTH1, HSPA6, ITGAM, ABTB1, TPM2, TNFAIP6, NLRC4, DDX60L, CXCL1, ORM1, RN7SL288P, TDP2, MYH6, NEMF, PRMT5-AS1, and MDGA2.', 'Top genes are FTH1, ABTB1, CXCL1, HSPA6, TNFAIP6, ITGAM, TNNI2, ELF2, RP11-750H9.5, DDX60L, CYTH4, CCDC9, PGLYRP1, EGR3, PI3, and PDCD10.'], Label: 0.8597837090492249\n",
      "Texts: ['Top genes are FTH1, SELE, ACKR1, STC1, CXCL1, IL6, A2M, EGR3, NEMF, AMZ2P1, LIMS2, POSTN, CCL2, SNORD58, RP11-111A21.1, and TRAJ3.', 'Top genes are IGKC, IGHM, RP11-1012A1.10, FTH1, PRKCE, IGHD, IGKV3-15, IGHV1-69-2, RNU7-50P, RNU7-18P, GLB1, RNU6-190P, Y_RNA_ENSG00000252894, JCHAIN, MTFR1L, and THBS4.'], Label: -0.06311988830566406\n",
      "Texts: ['Top genes are RNA5SP151, CTD-2126E3.5, EREG, RN7SL288P, FGD3, CPA2, DDX27, SLC31A1, TMEM52B, TP53BP1, RP11-141A19.1, RNU7-41P, RP11-562L8.1, ENSG00000212270.1, GZMB, and CTSG.', 'Top genes are KRT13, KRT14, KRT16, KRT6A, S100A7, SPRR2A, S100A2, SPRR2E, SPRR3, IGKC, CSTA, SPRR2D, KRT6B, FTH1, SPRR1B, and IGHA1.'], Label: -0.12537738680839539\n",
      "Texts: ['Top genes are SPP1, FTH1, EREG, CXCL3, CCL20, CCL4L2, CCL3L1, CCL2, BCYRN1, A2M, FN1, EMC10, AMZ2P1, TNFAIP6, TFEC, and TPM2.', 'Top genes are FTH1, IGKC, UBE2D2, EXOSC6, SUZ12, IGLC2, MTG2, DDX60L, TYW1, TLK1, CRYBG1, POLR3B, PISD, ABTB1, LAMB2P1, and ZNF131.'], Label: -0.10433273762464523\n",
      "Texts: ['Top genes are FTH1, IGKC, A2M, IGHA2, PHC3, CYTH4, TFEC, PDCD10, NEMF, ELF2, SAA1, TLK1, U47924.31, IGLC2, TPM2, and CXCL3.', 'Top genes are FTH1, NEMF, ARHGAP45, A2M, PHC3, PTPRJ, FARS2, CTD-2031P19.4, RPS27AP5, FLJ42393, RPL7P13, RP11-111A21.1, RNU7-41P, IGHA2, RP11-562L8.1, and ENSG00000212270.1.'], Label: 0.6354924440383911\n",
      "Texts: ['Top genes are ACTA2, MYH11, TPM2, FTH1, RGS5_ENSG00000143248, A2M, FN1, DES, ACTG2, WWTR1, FUNDC2, BCYRN1, MYOZ1, LAMB2, EMC10, and NFIX.', 'Top genes are FTH1, NEMF, EXOSC6, FUNDC2, IGHA1, CRYBG1, ZNF131, IGLC3, IGKC, LRRC14, SNORD58, RP11-111A21.1, RNU7-41P, RP11-562L8.1, ENSG00000212270.1, and GZMB.'], Label: -0.12603524327278137\n",
      "Texts: ['Top genes are FTH1, ALDOB, SPP1, MMP7, TFEC, MT1G, UBE2D2, NEMF, NAPSA, PIK3CB, FUNDC2, LINC01320, FABP1, SMC3, TDP2, and PRPS2.', 'Top genes are SCGB3A1, OLFM4, FTH1, LCN2, PSCA, AZGP1, UBE2D2, CRYBG1, MSMB, ACP3, KLK3, DDX60L, TDP2, NEMF, SUZ12, and PDCD10.'], Label: 0.08587698638439178\n",
      "Texts: ['Top genes are FTH1, NEMF, PDCD10, SUZ12, IGLC3, PRH1, TYW1, ATG3, PGM2L1, LIMS2, MED15, ARHGAP45, RP11-35O15.2, SNORD58, RPS20P33, and RP11-111A21.1.', 'Top genes are FTH1, PLA2G2A, RNU6-190P, RP11-295B17.6, H2BC12, Y_RNA_ENSG00000206756, EXOSC10, MYOC, GAL3ST4, FN1, RBP4, TLK1, PDCD10, RAB7B, LAMB2, and MT1G.'], Label: 0.11803219467401505\n",
      "Texts: ['Top genes are FTH1, KRT6A, KRT3, SPRR2A, SERPINB2, SPRR2D, KRT17, KRT12, LCN2, CSTA, SPRR2E, LINC00707, EREG, SPRR1B, CRYBG1, and S100A2.', 'Top genes are PRPS2, CYTH4, RP11-295B17.6, TLK1, CRYBG1, FTH1, CCDC9, RP11-334C17.5, CTNNAL1, NEMF, ACCS, DDX27, RNU7-41P, FGD3, EGR3, and PHC3.'], Label: -0.07578463852405548\n",
      "Texts: ['Top genes are IGKC, FTH1, IGHM, IGLC2, IGHA1, DDX27, SMC3, IGHD, TFEC, UBE2D2, PRPS2, FUNDC2, SUZ12, IGKV2D-29, IGLC3, and TLK1.', 'Top genes are FTH1, S100A2, SFTPC, SCGB1A1, KRT17, CCL18, CSTA, PGC, SUZ12, NAPSA, SFTPA1, SCGB3A2, EXOSC10, ATG3, EREG, and IGKC.'], Label: -0.14318303763866425\n"
     ]
    }
   ],
   "source": [
    "for example in train_examples[:10]:\n",
    "    print(f'Texts: {example.texts}, Label: {example.label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "52ef59e3-9a67-4278-b780-6152c2bf9425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "434250"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "287ac4ab-1c02-45f0-8036-4a5d11ea86fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e624c96a29f45d9925ab2350c5c0905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b34b9d06eaf449ab9385ca2ad64b2d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/27079 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Sample Training\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import evaluation\n",
    "from sentence_transformers import SentenceTransformer, models, losses\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "shuffle(train_examples)  # Shuffle the dataset before splitting\n",
    "validation_size = 1000\n",
    "validation_examples = train_examples[:validation_size]\n",
    "train_examples = train_examples[validation_size:]\n",
    "\n",
    "# Convert datasets to DataLoaders\n",
    "train_dataloader = DataLoader(train_examples, batch_size=16, shuffle=True)\n",
    "\n",
    "# Define the loss function\n",
    "train_loss = losses.CosineSimilarityLoss(model=model)\n",
    "\n",
    "# Define an evaluator (if you have a dev set)\n",
    "dev_evaluator = evaluation.EmbeddingSimilarityEvaluator.from_input_examples(validation_examples, name='dev')\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=1,\n",
    "    warmup_steps=100,\n",
    "    evaluator=dev_evaluator,\n",
    "    evaluation_steps=1000,\n",
    "    output_path='output/finetuned_model'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ffd7b306-1545-4d9f-8d79-70abc93118ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: [[0.8947206]]\n"
     ]
    }
   ],
   "source": [
    "sentences = ['Sentence one here.', 'Sentence two here.']\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "# Calculate similarity between embeddings\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity = cosine_similarity([embeddings[0]], [embeddings[1]])\n",
    "print(\"Cosine Similarity:\", similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d1092195-9e8f-48d2-8b4f-03843eca2277",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = 'output/interim_model'\n",
    "\n",
    "# Save the model manually\n",
    "model.save(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e49bfd-3659-4b27-b63b-c1f8eb33c7e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
